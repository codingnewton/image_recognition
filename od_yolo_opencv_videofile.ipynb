{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and show video in new window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840.0, 2160.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m((cap\u001b[38;5;241m.\u001b[39mget(cv\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_WIDTH),cap\u001b[38;5;241m.\u001b[39mget(cv\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_HEIGHT)))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m----> 8\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# if frame is read correctly ret is True\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture('2053100-uhd_3840_2160_30fps.mp4')\n",
    "cv.namedWindow('frame', cv.WINDOW_NORMAL)\n",
    "print((cap.get(cv.CAP_PROP_FRAME_WIDTH),cap.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    frame_resized = cv.resize(frame, (960, 540))\n",
    "    # gray = cv.cvtColor(frame_resized, cv.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv.imshow('frame', frame_resized)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and do object detection on video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "yolo = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video capture, this uses the webcam to do OD\n",
    "# Change here to read an MP4 file instead for our use case\n",
    "videoCap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to get class colors from an unique ID to RGB\n",
    "# E.g.: an input of cls_num = 5 (class ID) will return (1, 255, 1), which is a bright green with a slight blue tint\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)\n",
    "\n",
    "while True:\n",
    "    ret, frame = videoCap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    results = yolo.track(frame, stream=True)\n",
    "\n",
    "    for result in results:\n",
    "        # get the classes names\n",
    "        classes_names = result.names\n",
    "\n",
    "        # iterate over each box\n",
    "        for box in result.boxes:\n",
    "            # check if confidence is greater than 40 percent\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # get the class\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # get the class name\n",
    "                class_name = classes_names[cls]\n",
    "\n",
    "                # get the respective colour\n",
    "                colour = getColours(cls)\n",
    "\n",
    "                # draw the rectangle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
    "\n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(frame, f'{classes_names[int(box.cls[0])]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                \n",
    "    # show the image\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# release the video capture and destroy all windows\n",
    "videoCap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 304.0ms\n",
      "Speed: 11.2ms preprocess, 304.0ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 294.7ms\n",
      "Speed: 2.0ms preprocess, 294.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 301.7ms\n",
      "Speed: 11.6ms preprocess, 301.7ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 312.6ms\n",
      "Speed: 9.4ms preprocess, 312.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 328.8ms\n",
      "Speed: 0.0ms preprocess, 328.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 286.7ms\n",
      "Speed: 4.0ms preprocess, 286.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 286.3ms\n",
      "Speed: 5.5ms preprocess, 286.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 290.1ms\n",
      "Speed: 8.2ms preprocess, 290.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 293.4ms\n",
      "Speed: 7.5ms preprocess, 293.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 306.7ms\n",
      "Speed: 11.1ms preprocess, 306.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 212.1ms\n",
      "Speed: 0.5ms preprocess, 212.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 173.0ms\n",
      "Speed: 8.3ms preprocess, 173.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 189.3ms\n",
      "Speed: 0.0ms preprocess, 189.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 179.5ms\n",
      "Speed: 8.0ms preprocess, 179.5ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 181.2ms\n",
      "Speed: 0.0ms preprocess, 181.2ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 motorcycles, 1 stop sign, 1 cell phone, 172.2ms\n",
      "Speed: 8.2ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 173.5ms\n",
      "Speed: 8.6ms preprocess, 173.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 cell phone, 172.2ms\n",
      "Speed: 0.0ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 175.4ms\n",
      "Speed: 0.0ms preprocess, 175.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 165.2ms\n",
      "Speed: 3.5ms preprocess, 165.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 motorcycles, 1 cell phone, 173.3ms\n",
      "Speed: 7.3ms preprocess, 173.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 171.9ms\n",
      "Speed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 165.7ms\n",
      "Speed: 2.0ms preprocess, 165.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 167.4ms\n",
      "Speed: 5.5ms preprocess, 167.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 164.5ms\n",
      "Speed: 8.3ms preprocess, 164.5ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 train, 1 cell phone, 169.6ms\n",
      "Speed: 0.0ms preprocess, 169.6ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 164.7ms\n",
      "Speed: 7.9ms preprocess, 164.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 cell phone, 171.9ms\n",
      "Speed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 train, 1 cell phone, 246.4ms\n",
      "Speed: 9.0ms preprocess, 246.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 bus, 1 cell phone, 172.5ms\n",
      "Speed: 8.3ms preprocess, 172.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 181.2ms\n",
      "Speed: 0.0ms preprocess, 181.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 airplane, 172.0ms\n",
      "Speed: 7.8ms preprocess, 172.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 169.8ms\n",
      "Speed: 3.1ms preprocess, 169.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 170.9ms\n",
      "Speed: 1.3ms preprocess, 170.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 182.5ms\n",
      "Speed: 0.0ms preprocess, 182.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 174.0ms\n",
      "Speed: 6.2ms preprocess, 174.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 180.9ms\n",
      "Speed: 0.0ms preprocess, 180.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 178.5ms\n",
      "Speed: 2.6ms preprocess, 178.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 171.3ms\n",
      "Speed: 2.5ms preprocess, 171.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 umbrella, 178.7ms\n",
      "Speed: 4.0ms preprocess, 178.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 172.2ms\n",
      "Speed: 8.8ms preprocess, 172.2ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 airplanes, 1 cell phone, 186.8ms\n",
      "Speed: 1.6ms preprocess, 186.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 232.4ms\n",
      "Speed: 4.1ms preprocess, 232.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 airplane, 1 cell phone, 200.6ms\n",
      "Speed: 2.9ms preprocess, 200.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 188.7ms\n",
      "Speed: 8.2ms preprocess, 188.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 176.8ms\n",
      "Speed: 0.0ms preprocess, 176.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 skateboard, 1 cell phone, 182.4ms\n",
      "Speed: 0.0ms preprocess, 182.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 177.0ms\n",
      "Speed: 0.0ms preprocess, 177.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 179.0ms\n",
      "Speed: 0.0ms preprocess, 179.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 178.0ms\n",
      "Speed: 3.3ms preprocess, 178.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 176.9ms\n",
      "Speed: 4.7ms preprocess, 176.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 180.5ms\n",
      "Speed: 0.0ms preprocess, 180.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 1 cell phone, 171.6ms\n",
      "Speed: 0.0ms preprocess, 171.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 1 cell phone, 164.6ms\n",
      "Speed: 8.1ms preprocess, 164.6ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 175.5ms\n",
      "Speed: 0.0ms preprocess, 175.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 171.4ms\n",
      "Speed: 10.2ms preprocess, 171.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 1 cell phone, 184.6ms\n",
      "Speed: 3.9ms preprocess, 184.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 1 cell phone, 194.8ms\n",
      "Speed: 0.0ms preprocess, 194.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 truck, 1 umbrella, 1 cell phone, 173.0ms\n",
      "Speed: 1.0ms preprocess, 173.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 skateboard, 1 cell phone, 179.3ms\n",
      "Speed: 0.0ms preprocess, 179.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 cell phone, 181.1ms\n",
      "Speed: 0.0ms preprocess, 181.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 truck, 1 cell phone, 180.4ms\n",
      "Speed: 0.0ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 trucks, 1 cell phone, 180.9ms\n",
      "Speed: 9.1ms preprocess, 180.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 truck, 1 cell phone, 181.9ms\n",
      "Speed: 0.0ms preprocess, 181.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 truck, 1 cell phone, 173.1ms\n",
      "Speed: 3.1ms preprocess, 173.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 truck, 1 cell phone, 176.3ms\n",
      "Speed: 4.2ms preprocess, 176.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 169.9ms\n",
      "Speed: 9.9ms preprocess, 169.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 1 cell phone, 172.9ms\n",
      "Speed: 1.2ms preprocess, 172.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 176.6ms\n",
      "Speed: 8.3ms preprocess, 176.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 176.0ms\n",
      "Speed: 6.0ms preprocess, 176.0ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 175.4ms\n",
      "Speed: 8.4ms preprocess, 175.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 177.8ms\n",
      "Speed: 3.5ms preprocess, 177.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 175.4ms\n",
      "Speed: 6.0ms preprocess, 175.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 176.1ms\n",
      "Speed: 8.7ms preprocess, 176.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 171.5ms\n",
      "Speed: 8.8ms preprocess, 171.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 175.2ms\n",
      "Speed: 0.0ms preprocess, 175.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 180.7ms\n",
      "Speed: 0.0ms preprocess, 180.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 178.9ms\n",
      "Speed: 1.1ms preprocess, 178.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 177.0ms\n",
      "Speed: 9.5ms preprocess, 177.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 183.0ms\n",
      "Speed: 8.0ms preprocess, 183.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 171.6ms\n",
      "Speed: 0.0ms preprocess, 171.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 167.7ms\n",
      "Speed: 3.8ms preprocess, 167.7ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 171.8ms\n",
      "Speed: 9.3ms preprocess, 171.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 184.6ms\n",
      "Speed: 4.4ms preprocess, 184.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 193.7ms\n",
      "Speed: 0.0ms preprocess, 193.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 181.2ms\n",
      "Speed: 4.0ms preprocess, 181.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 182.3ms\n",
      "Speed: 0.0ms preprocess, 182.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 179.5ms\n",
      "Speed: 0.0ms preprocess, 179.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 172.5ms\n",
      "Speed: 3.3ms preprocess, 172.5ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 197.2ms\n",
      "Speed: 5.5ms preprocess, 197.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 175.0ms\n",
      "Speed: 5.0ms preprocess, 175.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 182.1ms\n",
      "Speed: 7.3ms preprocess, 182.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 172.3ms\n",
      "Speed: 6.0ms preprocess, 172.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 182.5ms\n",
      "Speed: 0.0ms preprocess, 182.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 181.3ms\n",
      "Speed: 0.0ms preprocess, 181.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 1 cell phone, 185.7ms\n",
      "Speed: 3.1ms preprocess, 185.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 244.4ms\n",
      "Speed: 8.1ms preprocess, 244.4ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 184.1ms\n",
      "Speed: 0.0ms preprocess, 184.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 bench, 1 cell phone, 189.7ms\n",
      "Speed: 0.0ms preprocess, 189.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 171.0ms\n",
      "Speed: 2.3ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 173.7ms\n",
      "Speed: 8.1ms preprocess, 173.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 172.6ms\n",
      "Speed: 0.0ms preprocess, 172.6ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 165.0ms\n",
      "Speed: 5.5ms preprocess, 165.0ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 181.7ms\n",
      "Speed: 2.0ms preprocess, 181.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 191.2ms\n",
      "Speed: 0.0ms preprocess, 191.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 183.4ms\n",
      "Speed: 0.0ms preprocess, 183.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 178.8ms\n",
      "Speed: 7.4ms preprocess, 178.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 187.2ms\n",
      "Speed: 0.0ms preprocess, 187.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 170.5ms\n",
      "Speed: 0.0ms preprocess, 170.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 168.0ms\n",
      "Speed: 4.7ms preprocess, 168.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 motorcycle, 171.7ms\n",
      "Speed: 9.4ms preprocess, 171.7ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 motorcycle, 170.8ms\n",
      "Speed: 5.5ms preprocess, 170.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 183.0ms\n",
      "Speed: 4.5ms preprocess, 183.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 173.2ms\n",
      "Speed: 5.5ms preprocess, 173.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 truck, 202.5ms\n",
      "Speed: 0.0ms preprocess, 202.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 truck, 172.8ms\n",
      "Speed: 4.9ms preprocess, 172.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 170.0ms\n",
      "Speed: 0.5ms preprocess, 170.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 172.1ms\n",
      "Speed: 1.7ms preprocess, 172.1ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 197.4ms\n",
      "Speed: 0.0ms preprocess, 197.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 180.7ms\n",
      "Speed: 0.0ms preprocess, 180.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 183.1ms\n",
      "Speed: 0.0ms preprocess, 183.1ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 180.5ms\n",
      "Speed: 7.5ms preprocess, 180.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 189.3ms\n",
      "Speed: 8.0ms preprocess, 189.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 airplane, 1 cell phone, 177.9ms\n",
      "Speed: 0.0ms preprocess, 177.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 167.7ms\n",
      "Speed: 5.0ms preprocess, 167.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 170.2ms\n",
      "Speed: 0.0ms preprocess, 170.2ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 train, 1 cell phone, 173.4ms\n",
      "Speed: 2.2ms preprocess, 173.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 172.2ms\n",
      "Speed: 0.0ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 189.4ms\n",
      "Speed: 6.5ms preprocess, 189.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 181.4ms\n",
      "Speed: 0.0ms preprocess, 181.4ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 173.7ms\n",
      "Speed: 8.1ms preprocess, 173.7ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 180.9ms\n",
      "Speed: 5.9ms preprocess, 180.9ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 172.0ms\n",
      "Speed: 0.0ms preprocess, 172.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 181.6ms\n",
      "Speed: 5.1ms preprocess, 181.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 193.1ms\n",
      "Speed: 4.0ms preprocess, 193.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 200.0ms\n",
      "Speed: 0.0ms preprocess, 200.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 203.9ms\n",
      "Speed: 3.2ms preprocess, 203.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 train, 1 cell phone, 182.3ms\n",
      "Speed: 0.0ms preprocess, 182.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 train, 1 cell phone, 171.5ms\n",
      "Speed: 8.9ms preprocess, 171.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 173.3ms\n",
      "Speed: 3.7ms preprocess, 173.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 183.6ms\n",
      "Speed: 0.0ms preprocess, 183.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 train, 1 cell phone, 208.1ms\n",
      "Speed: 0.0ms preprocess, 208.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 180.0ms\n",
      "Speed: 6.0ms preprocess, 180.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 173.7ms\n",
      "Speed: 7.5ms preprocess, 173.7ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 206.1ms\n",
      "Speed: 6.4ms preprocess, 206.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 195.7ms\n",
      "Speed: 4.9ms preprocess, 195.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 181.7ms\n",
      "Speed: 3.9ms preprocess, 181.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 245.9ms\n",
      "Speed: 0.0ms preprocess, 245.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 179.4ms\n",
      "Speed: 4.4ms preprocess, 179.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 1 cell phone, 194.4ms\n",
      "Speed: 3.0ms preprocess, 194.4ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 187.2ms\n",
      "Speed: 0.0ms preprocess, 187.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 motorcycle, 180.8ms\n",
      "Speed: 0.0ms preprocess, 180.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 cell phone, 194.2ms\n",
      "Speed: 0.0ms preprocess, 194.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 217.0ms\n",
      "Speed: 5.8ms preprocess, 217.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 cell phone, 186.8ms\n",
      "Speed: 8.3ms preprocess, 186.8ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.7ms\n",
      "Speed: 6.1ms preprocess, 317.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 213.5ms\n",
      "Speed: 0.0ms preprocess, 213.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 181.0ms\n",
      "Speed: 5.3ms preprocess, 181.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 198.2ms\n",
      "Speed: 77.9ms preprocess, 198.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 177.2ms\n",
      "Speed: 3.4ms preprocess, 177.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 196.4ms\n",
      "Speed: 0.0ms preprocess, 196.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 train, 180.8ms\n",
      "Speed: 32.3ms preprocess, 180.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 180.7ms\n",
      "Speed: 0.0ms preprocess, 180.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 205.8ms\n",
      "Speed: 2.1ms preprocess, 205.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 179.8ms\n",
      "Speed: 5.4ms preprocess, 179.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 192.7ms\n",
      "Speed: 2.2ms preprocess, 192.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 221.4ms\n",
      "Speed: 10.9ms preprocess, 221.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 212.5ms\n",
      "Speed: 4.5ms preprocess, 212.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 179.1ms\n",
      "Speed: 2.6ms preprocess, 179.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 cell phone, 183.4ms\n",
      "Speed: 8.0ms preprocess, 183.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 181.2ms\n",
      "Speed: 5.5ms preprocess, 181.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 frisbee, 178.9ms\n",
      "Speed: 2.9ms preprocess, 178.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 175.4ms\n",
      "Speed: 2.2ms preprocess, 175.4ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 200.7ms\n",
      "Speed: 6.1ms preprocess, 200.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.1ms\n",
      "Speed: 7.8ms preprocess, 286.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.8ms\n",
      "Speed: 1.0ms preprocess, 295.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 train, 285.3ms\n",
      "Speed: 0.5ms preprocess, 285.3ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 288.5ms\n",
      "Speed: 6.0ms preprocess, 288.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 283.5ms\n",
      "Speed: 7.9ms preprocess, 283.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 train, 299.4ms\n",
      "Speed: 13.0ms preprocess, 299.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 train, 280.9ms\n",
      "Speed: 5.9ms preprocess, 280.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 287.3ms\n",
      "Speed: 8.9ms preprocess, 287.3ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 287.3ms\n",
      "Speed: 5.7ms preprocess, 287.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.9ms\n",
      "Speed: 5.1ms preprocess, 286.9ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 294.3ms\n",
      "Speed: 9.1ms preprocess, 294.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m frame_resized \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m960\u001b[39m, \u001b[38;5;241m540\u001b[39m))\n\u001b[0;32m     29\u001b[0m results \u001b[38;5;241m=\u001b[39m yolo\u001b[38;5;241m.\u001b[39mtrack(frame_resized, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# get the classes names\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     classes_names \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# iterate over each box\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\site-packages\\ultralytics\\engine\\predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, [], \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m profilers \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    244\u001b[0m     ops\u001b[38;5;241m.\u001b[39mProfile(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    245\u001b[0m     ops\u001b[38;5;241m.\u001b[39mProfile(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    246\u001b[0m     ops\u001b[38;5;241m.\u001b[39mProfile(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    247\u001b[0m )\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_predict_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\site-packages\\ultralytics\\engine\\predictor.py:404\u001b[0m, in \u001b[0;36mBasePredictor.run_callbacks\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs all registered callbacks for a specific event.\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mget(event, []):\n\u001b[1;32m--> 404\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\site-packages\\ultralytics\\trackers\\track.py:37\u001b[0m, in \u001b[0;36mon_predict_start\u001b[1;34m(predictor, persist)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrackers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m persist:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m tracker \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m cfg \u001b[38;5;241m=\u001b[39m IterableSimpleNamespace(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39myaml_load(tracker))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mtracker_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytetrack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbotsort\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\site-packages\\ultralytics\\utils\\checks.py:528\u001b[0m, in \u001b[0;36mcheck_yaml\u001b[1;34m(file, suffix, hard)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_yaml\u001b[39m(file, suffix\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m), hard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search/download YAML file (if necessary) and return path, checking suffix.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhard\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\site-packages\\ultralytics\\utils\\checks.py:518\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(file)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# search\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mROOT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m**\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m file))  \u001b[38;5;66;03m# find file\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m    520\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:22\u001b[0m, in \u001b[0;36mglob\u001b[1;34m(pathname, recursive)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglob\u001b[39m(pathname, \u001b[38;5;241m*\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of paths matching a pathname pattern.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    The pattern may contain simple shell-style wildcards a la\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    zero or more directories and subdirectories.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:74\u001b[0m, in \u001b[0;36m_iglob\u001b[1;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     glob_in_dir \u001b[38;5;241m=\u001b[39m _glob0\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirname \u001b[38;5;129;01min\u001b[39;00m dirs:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m glob_in_dir(dirname, basename, dironly):\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, name)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:75\u001b[0m, in \u001b[0;36m_iglob\u001b[1;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[0;32m     73\u001b[0m     glob_in_dir \u001b[38;5;241m=\u001b[39m _glob0\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirname \u001b[38;5;129;01min\u001b[39;00m dirs:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m glob_in_dir(dirname, basename, dironly):\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, name)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:113\u001b[0m, in \u001b[0;36m_glob2\u001b[1;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _isrecursive(pattern)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m pattern[:\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _rlistdir(dirname, dironly)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:145\u001b[0m, in \u001b[0;36m_rlistdir\u001b[1;34m(dirname, dironly)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m x\n\u001b[0;32m    144\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, x) \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m _rlistdir(path, dironly):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(x, y)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:145\u001b[0m, in \u001b[0;36m_rlistdir\u001b[1;34m(dirname, dironly)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m x\n\u001b[0;32m    144\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, x) \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m _rlistdir(path, dironly):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(x, y)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:145\u001b[0m, in \u001b[0;36m_rlistdir\u001b[1;34m(dirname, dironly)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m x\n\u001b[0;32m    144\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, x) \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m _rlistdir(path, dironly):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(x, y)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:140\u001b[0m, in \u001b[0;36m_rlistdir\u001b[1;34m(dirname, dironly)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rlistdir\u001b[39m(dirname, dironly):\n\u001b[1;32m--> 140\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[43m_listdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdironly\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ishidden(x):\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:136\u001b[0m, in \u001b[0;36m_listdir\u001b[1;34m(dirname, dironly)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_listdir\u001b[39m(dirname, dironly):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(_iterdir(dirname, dironly)) \u001b[38;5;28;01mas\u001b[39;00m it:\n\u001b[1;32m--> 136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\anaconda3\\envs\\env39\\lib\\glob.py:126\u001b[0m, in \u001b[0;36m_iterdir\u001b[1;34m(dirname, dironly)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(dirname) \u001b[38;5;28;01mas\u001b[39;00m it:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m--> 126\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dironly \u001b[38;5;129;01mor\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m    128\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "yolo = YOLO('yolov8s.pt')\n",
    "\n",
    "# Load the video capture, this uses the webcam to do OD\n",
    "cap = cv.VideoCapture('2053100-uhd_3840_2160_30fps.mp4')\n",
    "\n",
    "# Function to get class colors from an unique ID to RGB\n",
    "# E.g.: an input of cls_num = 5 (class ID) will return (1, 255, 1), which is a bright green with a slight blue tint\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    frame_resized = cv.resize(frame, (960, 540))\n",
    "    results = yolo.track(frame_resized, stream=True)\n",
    "\n",
    "    for result in results:\n",
    "        # get the classes names\n",
    "        classes_names = result.names\n",
    "\n",
    "        # iterate over each box\n",
    "        for box in result.boxes:\n",
    "            # check if confidence is greater than 40 percent\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # get the class\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # get the class name\n",
    "                class_name = classes_names[cls]\n",
    "\n",
    "                # get the respective colour\n",
    "                colour = getColours(cls)\n",
    "\n",
    "                # draw the rectangle\n",
    "                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), colour, 2)\n",
    "\n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(frame_resized, f'{classes_names[int(box.cls[0])]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                \n",
    "    # show the image\n",
    "    cv2.imshow('frame', frame_resized)\n",
    "\n",
    "    # break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture and destroy all windows\n",
    "videoCap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
